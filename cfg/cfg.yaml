# Hyperparameters for training

# General parameters
Temporal_dim: 1024
in_channels: 2
dropout: 0.2
drop_path: 0.2
in_type: "1d" # 1d or 2d

# Contrastive model
contrast_embed_dim: 512  # This is fixed based on the Encoder's convolution channels
num_contrast_blocks: 4
feature_dim: 128
num_contrast_layers: 16
nhead: 4
contrast_sequence_length: 512 # this is the number of time frames of the history feeded to the model
dim_feedforward: 512
time_step_weights: [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]
contrast_normalize_before: True
contrast_attention: True    # use pure attention (True) or attention with Conv1d (False) for Auto Regressive
num_frames_per_clip: 64    # number of frames per block for the encoder
Encoder_attention: True    # use attention (True) or without attention for Encoder residual blocks

# Temporal to Frequency model
num_T2F_encoder_layers: 4
num_T2F_encoder_blocks: 8
T2F_encoder_embed_dim: 1024
T2F_encoder_nhead: 8
T2F_encoder_sequence_length: 32
num_T2F_decoder_layers: 1
num_T2F_decoder_blocks: 4
T2F_decoder_embed_dim: 1024
T2F_decoder_nhead: 8
T2F_num_queries: 32 # number of queries for the decoder, should be equal to the number of encoder_sequence_length
T2F_num_classes: 8

# Diffusion model
diffu_num_trans_layers: 32
diffu_residual_trans: True
diffusion_repeat: 20 # number of times to repeat the diffusion process
diffusion_num_steps: 100 # number of steps for the diffusion process (Markov chain)
diffusion_schedule_mode: linear # linear or cosine
diffusion_embed_dim: 512